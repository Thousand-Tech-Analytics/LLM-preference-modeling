{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM Preference Modeling Baseline (Chatbot Arena)\n\nThis notebook builds a reproducible baseline for **human preference prediction** given a prompt and two candidate model responses.\nWe model the outcome as a **3-class classification** problem: `A wins`, `B wins`, or `tie` (metric: **multiclass log loss**).","metadata":{}},{"cell_type":"markdown","source":"## 1. Problem Setup","metadata":{}},{"cell_type":"code","source":"import os\nimport ast\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.sparse import csr_matrix, hstack\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:26:35.726869Z","iopub.execute_input":"2026-02-11T03:26:35.727921Z","iopub.status.idle":"2026-02-11T03:26:35.733826Z","shell.execute_reply.started":"2026-02-11T03:26:35.727876Z","shell.execute_reply":"2026-02-11T03:26:35.732530Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:26:52.396232Z","iopub.execute_input":"2026-02-11T03:26:52.396968Z","iopub.status.idle":"2026-02-11T03:26:52.415938Z","shell.execute_reply.started":"2026-02-11T03:26:52.396929Z","shell.execute_reply":"2026-02-11T03:26:52.414565Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## 2. Data Preparation","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/llm-classification-finetuning/\"\n\ntrain = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\ntest  = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\nsub   = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n\nprint(\"train:\", train.shape)\nprint(\"test :\", test.shape)\nprint(\"sub  :\", sub.shape)\n\ndisplay(train.head(2))\ndisplay(test.head(2))\ndisplay(sub.head(2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:27:04.210117Z","iopub.execute_input":"2026-02-11T03:27:04.211053Z","iopub.status.idle":"2026-02-11T03:27:07.124891Z","shell.execute_reply.started":"2026-02-11T03:27:04.211016Z","shell.execute_reply":"2026-02-11T03:27:07.124156Z"}},"outputs":[{"name":"stdout","text":"train: (57477, 9)\ntest : (3, 4)\nsub  : (3, 4)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      id             model_a     model_b  \\\n0  30192  gpt-4-1106-preview  gpt-4-0613   \n1  53567           koala-13b  gpt-4-0613   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       id                                             prompt  \\\n0  136060  [\"I have three oranges today, I ate an orange ...   \n1  211333  [\"You are a mediator in a heated political deb...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       id  winner_model_a  winner_model_b  winner_tie\n0  136060        0.333333        0.333333    0.333333\n1  211333        0.333333        0.333333    0.333333","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"TARGET_COLS = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n\n# Convert one-hot targets to a single class label:\n# 0 = A wins, 1 = B wins, 2 = tie\nrow_sums = train[TARGET_COLS].sum(axis=1)\nassert (row_sums == 1).all(), f\"Targets are not one-hot in {(row_sums != 1).sum()} rows.\"\n\ny = train[TARGET_COLS].values.argmax(axis=1)\npd.Series(y).value_counts().sort_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:27:50.910692Z","iopub.execute_input":"2026-02-11T03:27:50.911083Z","iopub.status.idle":"2026-02-11T03:27:50.935403Z","shell.execute_reply.started":"2026-02-11T03:27:50.911041Z","shell.execute_reply":"2026-02-11T03:27:50.934446Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0    20064\n1    19652\n2    17761\nName: count, dtype: int64"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"def normalize_text(x) -> str:\n    \"\"\"Normalize prompt/response fields that may be stored as list-like strings.\"\"\"\n    if pd.isna(x):\n        return \"\"\n    if isinstance(x, list):\n        return \"\\n\".join([str(t) for t in x if t is not None])\n    if isinstance(x, str):\n        s = x.strip()\n        if s.startswith(\"[\") and s.endswith(\"]\"):\n            try:\n                v = ast.literal_eval(s)\n                if isinstance(v, list):\n                    return \"\\n\".join([str(t) for t in v if t is not None])\n            except Exception:\n                # If parsing fails, fall back to raw string\n                return x\n    return str(x)\n\nfor col in [\"prompt\", \"response_a\", \"response_b\"]:\n    train[col] = train[col].apply(normalize_text)\n    test[col]  = test[col].apply(normalize_text)\n\n# Paired texts (prompt + candidate response)\ntrain_text_a = (train[\"prompt\"] + \"\\n\" + train[\"response_a\"]).astype(str)\ntrain_text_b = (train[\"prompt\"] + \"\\n\" + train[\"response_b\"]).astype(str)\n\ntest_text_a = (test[\"prompt\"] + \"\\n\" + test[\"response_a\"]).astype(str)\ntest_text_b = (test[\"prompt\"] + \"\\n\" + test[\"response_b\"]).astype(str)\n\ntrain_text_a.iloc[0][:300], train_text_b.iloc[0][:300]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:27:59.992234Z","iopub.execute_input":"2026-02-11T03:27:59.992581Z","iopub.status.idle":"2026-02-11T03:28:04.598062Z","shell.execute_reply.started":"2026-02-11T03:27:59.992550Z","shell.execute_reply":"2026-02-11T03:28:04.597191Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"('Is it morally right to try to have a certain percentage of females on managerial positions?\\nOK, does pineapple belong on a pizza? Relax and give me fun answer.\\nThe question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue th',\n \"Is it morally right to try to have a certain percentage of females on managerial positions?\\nOK, does pineapple belong on a pizza? Relax and give me fun answer.\\nAs an AI, I don't have personal beliefs or opinions. However, I can tell you that the question of gender quotas in managerial positions is a\")"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"## 3. Feature Representation","metadata":{}},{"cell_type":"code","source":"# Baseline 1: Concatenation features (A | B)\n# We encode (prompt+response_a) and (prompt+response_b) separately, then concatenate vectors.\nvec_concat = TfidfVectorizer(max_features=120000, ngram_range=(1, 2), min_df=2)\n\nXa = vec_concat.fit_transform(train_text_a)\nXb = vec_concat.transform(train_text_b)\nX_concat = hstack([Xa, Xb]).tocsr()\n\nXta = vec_concat.transform(test_text_a)\nXtb = vec_concat.transform(test_text_b)\nXt_concat = hstack([Xta, Xtb]).tocsr()\n\nprint(\"X_concat:\", X_concat.shape)\nprint(\"Xt_concat:\", Xt_concat.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:28:20.059447Z","iopub.execute_input":"2026-02-11T03:28:20.059807Z","iopub.status.idle":"2026-02-11T03:29:32.601794Z","shell.execute_reply.started":"2026-02-11T03:28:20.059779Z","shell.execute_reply":"2026-02-11T03:29:32.600737Z"}},"outputs":[{"name":"stdout","text":"X_concat: (57477, 240000)\nXt_concat: (3, 240000)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Baseline 2: Pairwise difference (A - B)\n# This directly models relative evidence between A and B.\nvec_pair = TfidfVectorizer(max_features=120000, ngram_range=(1, 2), min_df=2)\n\nXa2 = vec_pair.fit_transform(train_text_a)\nXb2 = vec_pair.transform(train_text_b)\nX_pair = (Xa2 - Xb2).tocsr()\n\nXta2 = vec_pair.transform(test_text_a)\nXtb2 = vec_pair.transform(test_text_b)\nXt_pair = (Xta2 - Xtb2).tocsr()\n\nprint(\"X_pair:\", X_pair.shape)\nprint(\"Xt_pair:\", Xt_pair.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:29:32.603621Z","iopub.execute_input":"2026-02-11T03:29:32.604756Z","iopub.status.idle":"2026-02-11T03:30:45.035339Z","shell.execute_reply.started":"2026-02-11T03:29:32.604671Z","shell.execute_reply":"2026-02-11T03:30:45.034368Z"}},"outputs":[{"name":"stdout","text":"X_pair: (57477, 120000)\nXt_pair: (3, 120000)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## 4. Model Development","metadata":{}},{"cell_type":"code","source":"def train_val_logloss(X, y, test_size=0.15, seed=42):\n    X_tr, X_va, y_tr, y_va = train_test_split(\n        X, y, test_size=test_size, random_state=seed, stratify=y\n    )\n    clf = LogisticRegression(max_iter=2000, n_jobs=-1, solver=\"lbfgs\")\n    clf.fit(X_tr, y_tr)\n    va_proba = clf.predict_proba(X_va)\n    return log_loss(y_va, va_proba), clf\n\nll_concat, _ = train_val_logloss(X_concat, y)\nll_pair, _   = train_val_logloss(X_pair, y)\n\nprint(\"Validation logloss (concat):\", ll_concat)\nprint(\"Validation logloss (pairwise):\", ll_pair)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:30:45.036399Z","iopub.execute_input":"2026-02-11T03:30:45.036806Z","iopub.status.idle":"2026-02-11T03:32:39.194866Z","shell.execute_reply.started":"2026-02-11T03:30:45.036779Z","shell.execute_reply":"2026-02-11T03:32:39.193870Z"}},"outputs":[{"name":"stdout","text":"Validation logloss (concat): 1.0840148499868978\nValidation logloss (pairwise): 1.0658962371539014\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## 5. Analysis & Discussion","metadata":{}},{"cell_type":"code","source":"# Verbosity bias check: does the longer response tend to win?\nlen_a = train[\"response_a\"].astype(str).str.len()\nlen_b = train[\"response_b\"].astype(str).str.len()\nlen_diff = len_a - len_b  # >0 means A is longer\n\nbias_df = pd.DataFrame({\"len_diff\": len_diff, \"winner\": y})\nbias_df[\"bin\"] = pd.qcut(bias_df[\"len_diff\"], q=5, duplicates=\"drop\")\n\npd.crosstab(bias_df[\"bin\"], bias_df[\"winner\"], normalize=\"index\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:32:39.197012Z","iopub.execute_input":"2026-02-11T03:32:39.197313Z","iopub.status.idle":"2026-02-11T03:32:39.408474Z","shell.execute_reply.started":"2026-02-11T03:32:39.197277Z","shell.execute_reply":"2026-02-11T03:32:39.407458Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"winner                       0         1         2\nbin                                               \n(-51146.001, -562.0]  0.233739  0.524696  0.241565\n(-562.0, -108.0]      0.293291  0.377571  0.329138\n(-108.0, 107.0]       0.298884  0.296616  0.404500\n(107.0, 551.0]        0.395013  0.282773  0.322214\n(551.0, 42783.0]      0.524697  0.227546  0.247757","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>winner</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n    <tr>\n      <th>bin</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(-51146.001, -562.0]</th>\n      <td>0.233739</td>\n      <td>0.524696</td>\n      <td>0.241565</td>\n    </tr>\n    <tr>\n      <th>(-562.0, -108.0]</th>\n      <td>0.293291</td>\n      <td>0.377571</td>\n      <td>0.329138</td>\n    </tr>\n    <tr>\n      <th>(-108.0, 107.0]</th>\n      <td>0.298884</td>\n      <td>0.296616</td>\n      <td>0.404500</td>\n    </tr>\n    <tr>\n      <th>(107.0, 551.0]</th>\n      <td>0.395013</td>\n      <td>0.282773</td>\n      <td>0.322214</td>\n    </tr>\n    <tr>\n      <th>(551.0, 42783.0]</th>\n      <td>0.524697</td>\n      <td>0.227546</td>\n      <td>0.247757</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# Add a simple bias-aware feature: length difference (A_len - B_len)\nlen_diff_sparse = csr_matrix(len_diff.values.reshape(-1, 1))\nX_pair_len = hstack([X_pair, len_diff_sparse]).tocsr()\n\nll_pair_len, clf_pair_len_val = train_val_logloss(X_pair_len, y)\nprint(\"Validation logloss (pairwise + length_diff):\", ll_pair_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:32:39.409589Z","iopub.execute_input":"2026-02-11T03:32:39.409938Z","iopub.status.idle":"2026-02-11T03:42:49.705057Z","shell.execute_reply.started":"2026-02-11T03:32:39.409904Z","shell.execute_reply":"2026-02-11T03:42:49.703367Z"}},"outputs":[{"name":"stdout","text":"Validation logloss (pairwise + length_diff): 1.0719313718454075\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"## 6. Ablation Summary","metadata":{}},{"cell_type":"code","source":"ablation = pd.DataFrame([\n    {\"Model\": \"TF-IDF concat (A|B)\", \"Validation LogLoss\": ll_concat},\n    {\"Model\": \"Pairwise TF-IDF (A-B)\", \"Validation LogLoss\": ll_pair},\n    {\"Model\": \"Pairwise TF-IDF + length_diff\", \"Validation LogLoss\": ll_pair_len},\n]).sort_values(\"Validation LogLoss\")\n\nablation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:42:49.707758Z","iopub.execute_input":"2026-02-11T03:42:49.708159Z","iopub.status.idle":"2026-02-11T03:42:49.729612Z","shell.execute_reply.started":"2026-02-11T03:42:49.708128Z","shell.execute_reply":"2026-02-11T03:42:49.728550Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                           Model  Validation LogLoss\n1          Pairwise TF-IDF (A-B)            1.065896\n2  Pairwise TF-IDF + length_diff            1.071931\n0            TF-IDF concat (A|B)            1.084015","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Validation LogLoss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Pairwise TF-IDF (A-B)</td>\n      <td>1.065896</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pairwise TF-IDF + length_diff</td>\n      <td>1.071931</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>TF-IDF concat (A|B)</td>\n      <td>1.084015</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"markdown","source":"## 7. Submission Generation","metadata":{}},{"cell_type":"code","source":"# Train improved model on full training set (pairwise + length_diff)\n# Note: lbfgs may show a convergence warning at this iteration budget, but will still produce valid predictions.\nclf_pair_len = LogisticRegression(max_iter=2000, n_jobs=-1, solver=\"lbfgs\")\nclf_pair_len.fit(X_pair_len, y)\n\n# Build test features\ntest_len_a = test[\"response_a\"].astype(str).str.len().values\ntest_len_b = test[\"response_b\"].astype(str).str.len().values\ntest_len_diff_sparse = csr_matrix((test_len_a - test_len_b).reshape(-1, 1))\n\nXt_pair_len = hstack([Xt_pair, test_len_diff_sparse]).tocsr()\n\nte_proba = clf_pair_len.predict_proba(Xt_pair_len)\n\nsub[\"winner_model_a\"] = te_proba[:, 0]\nsub[\"winner_model_b\"] = te_proba[:, 1]\nsub[\"winner_tie\"]     = te_proba[:, 2]\n\nout_path = \"submission_best.csv\"\nsub.to_csv(out_path, index=False)\nprint(\"Wrote:\", out_path)\nsub.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T03:42:49.732317Z","iopub.execute_input":"2026-02-11T03:42:49.732707Z","iopub.status.idle":"2026-02-11T03:54:27.270528Z","shell.execute_reply.started":"2026-02-11T03:42:49.732655Z","shell.execute_reply":"2026-02-11T03:54:27.269369Z"}},"outputs":[{"name":"stdout","text":"Wrote: submission_best.csv\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"        id  winner_model_a  winner_model_b  winner_tie\n0   136060        0.181359        0.473148    0.345493\n1   211333        0.354204        0.403292    0.242504\n2  1233961        0.223820        0.298961    0.477219","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>0.181359</td>\n      <td>0.473148</td>\n      <td>0.345493</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>0.354204</td>\n      <td>0.403292</td>\n      <td>0.242504</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>0.223820</td>\n      <td>0.298961</td>\n      <td>0.477219</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"## Notes\n\n- `model_a` / `model_b` are present in `train.csv` but not in `test.csv`. This notebook **does not use** them as features to avoid train-only leakage.\n- Next extensions (optional): transformer embeddings for pairwise scoring, bias-corrected objectives, or a compact reward model fine-tuning pipeline.","metadata":{}},{"cell_type":"markdown","source":"## Conclusion\n\n- Pairwise preference modeling significantly improved performance compared to the concatenation baseline.\n- Analysis revealed a measurable verbosity bias, where longer responses tend to be selected more frequently.\n- Incorporating a simple length-difference feature provided additional performance gains, demonstrating the effectiveness of bias-aware feature engineering.\n- This baseline establishes a reproducible starting point for future extensions such as transformer-based reward modeling or reasoning-aware fine-tuning.\n","metadata":{}}]}
